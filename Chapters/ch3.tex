\section{TOPOLOGY OF THE COMPLEX PLANE}
\subsection{Neighborhoods, Open and Closed Sets}
\begin{definition}[Open Disk]
The \emph{open disk} of radius $r$ around the point $p$ is defined as follows:
\begin{equation*}\disk{r}{p} = \{z \in \C \mid \modulus{z-p} < r\}\end{equation*}
\end{definition}
\begin{definition}[Neighborhood of a Point]
A set $S \subseteq \C$ is called a \emph{neighborhood} of a point $p$ if there exists some $r > 0$ such that $\disk{p}{r} \subseteq S$.
We write this as $S \in \nbhd{p}$, where $\nbhd{p}$ denotes the \emph{neighborhood-system} of $p$.
\end{definition}
\begin{definition}[Punctured Disk]
The \emph{punctured disk} of radius $r$ around the point $p$ is defined as follows:
\begin{equation*}\pdisk{r}{p} = \{z \in \C \mid 0<\modulus{z-p} < r\}\end{equation*}
\end{definition}
\begin{definition}[Punctured Neighborhood of a Point]
A set $S \subseteq \C$ is called a \emph{punctured neighborhood} of a point $p$ if there exists some $r > 0$ such that $\pdisk{p}{r} \subseteq S$ and $p \notin S$.
We write this as $S \in \pnbhd{p}$, where $\pnbhd{p}$ denotes the \emph{punctured neighborhood-system} of $p$.
\end{definition}
\begin{definition}[Open Set]
A set $S$ is called an \emph{open set} iff $\forall z \in S, S \in \nbhd{z}$.
\end{definition}
\begin{lemma}[Open Disks are Open Sets]
Any open disk $\disk{p}{r}$ is an open set.
\end{lemma}
\begin{proof}
We need to show that $\disk{p}{r}$ is a neighborhood of everyone one of its points. Let $q \in \disk{p}{r}$. We can show that $\disk{q}{r-\modulus{p-q}} \subseteq \disk{p}{r}$. To do this, pick any point $z$ in the new disk. To show it's in our original disk, we need $\modulus{z-p} < r$. Since $z$ is in the second disk, we can write $\modulus{z-q} < r-\modulus{p-q}$. We can then use the triangle inequality to show that $\modulus{z-p} = \modulus{z-q+q-p} < \modulus{z-q}+\modulus{p-q} < r-\modulus{p-q}+\modulus{p-q} < r$. Therefore, our original open disk contains a smaller open disk around every point, making it a neighborhood of every one of its points, i.e. an open set.
\end{proof}
\begin{lemma}[Supersets of Neighborhoods]
If $N \in \nbhd{p}$ and $N \subseteq M$, $M \in \nbhd{p}$.
\end{lemma}
\begin{proof}
If $N \in \nbhd{p}$, then there exists some $\disk{p}{r} \subseteq N$. Since $N \subseteq M$, $\disk{p}{r} \subseteq M$. Therefore, $M \in \nbhd{p}$.
\end{proof}
\begin{lemma}[Properties of Open Sets]
The union of any collection of open sets is open, and the intersection of any \emph{finite} collection of open sets is open.
\end{lemma}
\begin{proof}
The union of any collection of sets is the set containing all of the points in all of the sets. Denote the union as $U$, and let $p$ be an element of one of the sets, $S$. Since $S$ is an open set, it is a neighborhood of $p$, and therefore there exists a $\disk{p}{r} \in S$.
Since $S$ is a subset of $U$, so is the disk, and since this is true of any point in the union, the union must be open.
If a point $p$ is in the intersection of a collection of sets $C$, it is in everyone one of the elements of the collection. Since each set in the collection is open, they are all neighborhoods of $p$. For every set $S$ in the collection, there is therefore some radius $r_S$ such that $\disk{p}{r_S} \in S$. Note that we can choose any radius less than or equal to $r_S$ and still get an open disk around $p$ fully contained in $S$
Since there are only finitely many sets in the collection, we can let $\varepsilon = \min r_S$, which will be greater than $0$. But since $\varepsilon \leq r_S$ for any $S$, $\disk{p}{\varepsilon}$ will be a subset of every $S$, and therefore will be in the intersection. The intersection is therefore a neighborhood of all of its points, making it an open set. 
\end{proof}
\begin{definition}[Closed Set]
A set $S \subseteq \C$ is called \emph{closed} iff its complement $S^C$ is open.
\end{definition}
\begin{lemma}[Properties of Closed Sets]
The intersection of any collection of closed sets is closed, and the union of any \emph{finite} collection of closed sets is closed.
\end{lemma}
\begin{proof}
This proof follows directly from De Morgan's Laws for sets and \hyperlink{Properties of Open Sets}{the union and intersection properties of open sets}.
\end{proof}
\begin{definition}[Topology on a Set]
Given any set $X$, a \emph{topology} on $X$ $\tau_X$ is a collection of subsets called open sets, which satisfy the following properties:
\begin{itemize}
\item $\emptyset \in \tau_X, X \in \tau_X$
\item The union of a collection of elements in $\tau_X$ is in $\tau_X$
\item The intersection of a \emph{finite} collection of elements in $\tau_X$ is in $\tau_X$
\end{itemize}
A neighborhood of a point $p$ in any general topology is a set which contains an open set containing $p$.
\end{definition}
\begin{definition}[Relative Topology]
Given any type of set in the topology of $\C$ (open set, closed set, open disk, punctured disk, etc.) and some fixed subset $X \subseteq \C$, we can define a type of set \emph{relative} to $X$ as the intersection of that type of set with $X$. For instance, if $N \in \nbhd{p}$ and $p \in X$, then the intersection $N \cap X$ is called a \emph{relative neighborhood} of $p$, denoted as $N \cap X \in \rnbhd{p}{X}$. The collection of all open sets relative to $X$ forms a topology, called the \emph{relative topology} of $X$.
\end{definition}
\subsection{Accumulation Points and the Closure of a Set}
\begin{definition}[Accumulation Point]
A point $p$ is called an \emph{accumulation point} or \emph{limit point} of a set $S$ iff there does not exist a neigborhood $N \in \nbhd{p}$ such that $N \cap S = \emptyset$.
\end{definition}
\begin{lemma}[Accumulation Points of a Closed Set]
$K \subseteq \C$ is closed iff it contains all of its accumulation points.
\end{lemma}
\begin{proof}
First, we will prove that a closed set contains all of its limit points.
Suppose for the sake of contradiction that there exists a $p$ which is an accumulation point of $K$ and is in $K^C$. Since $K$ is closed, its complement is open, and therefore is a neighborhood of every one of its points. $p \in K^C$, so $K^C \in \nbhd{p}$. Therefore, there exists some disk centered at $p$ which lies entirely in $K^C$. But this disk is a neighborhood of $p$ which does not contain any points in $K$, which means $p$ cannot be an accumulation point of $S$.
Now for the converse. Suppose $K$ contains all of its limit points. This means that there isn't a limit point of $K$ in $K^C$. Thus, for any point $p \in K^C$, there exists a neighborhood of $p$ which is entirely in $K^C$. But since \hyperlink{Supersets of Neighborhoods}{any superset of a neighborhood of $p$ is still a neighborhood of $p$}, $K^C \in \nbhd{p}$. $K^C$ is therefore a neighborhood of all of its points, meaning it is open, and $K$ is closed.
\end{proof}
\begin{definition}[Closure of a Set]
Given a set $S$, its \emph{closure} $\overline{S}$ is the union of $S$ and all of its accumulation points.
\end{definition}
\begin{lemma}[Closure of a Closed Set]
$K$ is a closed set iff $\overline{K} = K$.
\end{lemma}
\begin{proof}
Since the closure of a set is the set together with all of its accumulation points, a set equalling its closure means that the set contains all of its limit points. By a \hyperlink{Accumulation Points of a Closed Set}{previous lemma}, this is equivalent to the set being closed.
\end{proof}
\begin{lemma}[Closure of a Set is Closed]
The closure of any set $S$ is a closed set.
\end{lemma}
\begin{proof}
Let $p \in \left(\overline{S}\right)^C$. Since $p$ is not in $S$ nor is it a limit point, there exists a disk around $p$ which is entirely contained in $\left(\overline{S}\right)^C$. The entire complement of the closure is therefore the union of such open disks. But since \hyperlink{Open Disks are Open Sets}{an open disk is an open set} and \hyperlink{Properties of Open Sets}{the union of open sets is open}, the complement of the closure is open, meaning the closure is closed.
\end{proof}
\subsection{Interior, Exterior, and Boundary}
\begin{definition}[Interior of a Set]
Given any set $S$, its \emph{interior} $\interior{S}$ is defined as the complement of the closure of the complement of $S$.
\end{definition}
\begin{lemma}[Properties of the Interior]
If $S$ is some set, and $\interior{S}$ is its interior, the following will hold:
\begin{enumerate}
\item $\interior{S}$ is open.
\item \begin{equation*} \interior{S} = \{p \in S \mid S \in \nbhd{p}\}\end{equation*}
\end{enumerate}
\end{lemma}
\begin{proof}
The interior is an open set because it is the complement of the closure of some other set. Since \hyperlink{Closure of a Set}{the closure of a set is closed}, this means that the interior is open.
To prove the second part, take any point $p$ in the set where the set is a neighborhood of $p$. Clearly, $p$ is not in the complement of $S$. Since there is a neighborhood of $p$ which does not contain any points in the complement of $S$, namely $S$ itself, it is not a limit point of the complement of $S$. Therefore, $p$ is not in the complement of the closure, and therefore is in the complement of the closure of the complement, also called the interior.
\end{proof}
\begin{definition}[Exterior of a Set]
Given any set $S$, its \emph{exterior} $\exterior{S}$ is defined as the interior of its complement.
\end{definition}
\begin{definition}[Boundary of a Set]
Given any set $S$, its \emph{boundary} $\boundary{S}$ consists of all points not in the interior of exterior of $S$.
\end{definition}
\subsection{Sequences in the Complex Plane}
The notion of a \emph{sequence} is a very useful one in topology, since not only are sequences useful in proofs of topological properties, but the properties of sequences in a topological space can tell us about the topological space itself. Here, we will go over the basic properties of sequences in the complex plane.
\subsubsection{Basic Results on Sequences}
\begin{definition}[Sequence]
Given a set $S$, a \emph{sequence} in $S$ is a function $a : \mathbb{N} \longrightarrow S$. The sequence can be written as $\seq{a}$, and the $n$th member of the sequence is written $a_n$.
\end{definition}
\begin{definition}[Topological Limit of a Sequence]
If $\seq{a} \in S \subseteq X$ and $X$ has a topology, we say the sequence has a \emph{limit} of $a \in X$ iff for every $U \in \nbhd{a}$ there exists some natural number $N$ such that $n>N \implies a_n \in U$.
\end{definition}
\begin{definition}[Metric Limit of a Sequence]
If $\seq{a} \in S \subseteq \C$ we say the sequence has a \emph{limit} of $a \in \C$ iff for every $\varepsilon > 0$ there exists some natural number $N$ such that $n > N \implies \modulus{a_n-a} < \varepsilon$.
\end{definition}
\begin{theorem}[Equivalence of Limit Types for Sequences]
If $\seq{a} \in S \subseteq \C$ then the sequence has a topological limit of $a \in \C$ iff it has a metric limit of $a \in \C$.
\end{theorem}
\begin{proof}
First we will show that a topological limit implies a metric limit. We are given some $\varepsilon > 0$, and we need to find the corresponding $N$ such that all values in the sequence past $N$ are within $\varepsilon$ of $a$. This is equivalent to saying all of the values in the sequence past $N$ are in $\disk{a}{\varepsilon}$. This set is a neighborhood of $a$. Since we know the sequence converges topologically, we can find such an $N$.\\
Now we will show the converse: a metric limit implies a topological limit. We are given some $U \in \nbhd{a}$, and we need to find the corresponding $N$. Since $U$ is a neighborhood of $a$, there exists some $\disk{a}{r} \subseteq U$. Since we know there is a metric limit, we can find an $N$ such that all sequence elements past $N$ are within $r$ of $a$, i.e. in the disk. Since all of these points are in the disk, they are in $U$. Therefore, all points in the sequence past $N$ are in $U$, showing that the sequence converges to the same point topologically.
\end{proof}
\begin{definition}[Convergent Sequence]
A sequence is \emph{convergent} if it has a limit.
\end{definition}
\begin{definition}[Bounded Set]
A set $S \subseteq \C$ is \emph{bounded} if it is a subset of some disk centered around $0$.
\end{definition}
\begin{lemma}[Convergent Sequences are Bounded]
If $\seq{a}$ is a convergent sequence then its range is a \hyperlink{Bounded Set}{bounded set.}
\end{lemma}
\begin{proof}
Since $\seq{a}$ is convergent, we know it has a limit, which we'll call $a$. We can pick $\varepsilon = 1$ and find some $N$ such that all sequence members past $N$ are within $1$ unit of $a$. By the triangle inequality, this means they are in $\disk{0}{\modulus{a}+1}$. This disk includes all of the points after $N$, but not necessarily those before $N$. However, there are only finitely many sequence members before or at $N$, so we can take the maximum modulus of all of these points, which we'll call $R$. Therefore, all points are contained within $\disk{0}{\modulus{a}+R+2}$, so the sequence is bounded.
\end{proof}
\begin{theorem}[Uniqueness of Limits for Sequences]
If $\seq{a} \in S \subseteq \C$ has a limit of $a$, then it does not have any other limit.
\end{theorem}
\begin{proof}
Since $a_n \to a$, we know that for every $\varepsilon > 0$, there exists some cutoff point after which all elements of the sequence are within $\varepsilon$ of $a$. Now assume for contradiction that there is another point $\tilde{a}$ with the same property. Since these points are not equal, the distance between them is a positive number. Let $\varepsilon_0 = \frac{1}{2}\modulus{a-\tilde{a}}$. Since the sequence converges to both points, there is a corresponding cuttoff $N_{a}$ for $a$ and a cutoff $N_{\tilde{a}}$ for $\tilde{a}$. Now consider the following point:
\begin{equation*} p = a_{N_{a}+N_{\tilde{a}}+1} \end{equation*}
Since $p$ is beyond the cutoff for $a$, $\modulus{p-a}<\frac{1}{2}\modulus{\tilde{a}-a}$. But since $p$ is beyond the cutoff for $\tilde{a}$, $\modulus{p-\tilde{a}} < \frac{1}{2}\modulus{\tilde{a}-a}$. Adding these inequalities together, we get $\modulus{a-p}+\modulus{p-\tilde{a}} < \modulus{a-\tilde{a}}$. This violates the triangle inequality, so $\tilde{a}$ cannot be different from $a$.
\end{proof}
\begin{theorem}[Limit Laws for Sequences]
Suppose $\seq{a}$ and $\seq{b}$ are sequences in the complex plane with $\lim_{n\to\infty} a_n =a$ and $\lim_{n\to\infty} b_n = b$. Then we can conclude the following:
\begin{enumerate}
\item $$\lim_{n\to\infty} (a_n+b_n) = a+b$$
\item $$\lim_{n\to\infty} (a_nb_n) = ab$$
\item $$\lim_{n\to\infty} \frac{1}{a_n} = \frac{1}{a}$$ provided $a \neq 0$ and $a_n \neq 0$ for all $n$.
\item $$\lim_{n\to\infty} \rpart{a_n} = \rpart{a}$$\newline $$\lim_{n\to\infty} \ipart{a_n} = \ipart{a}$$ 
\item $$\lim_{n\to\infty} \modulus{a_n} = \modulus{a}$$
\end{enumerate}
\end{theorem}
\begin{proof}
\begin{enumerate}
\item We are given an $\varepsilon > 0$ and need to find the corresponding $N$. Since both sequences converge, let $N_a$ and $N_b$ be the cutoffs for each sequence corresponding to a distance of $\varepsilon/2$. Let $N = N_a + N_b + 1$. Now we can bound the distance from $a_N+b_N$ to $a+b$:
\begin{align*}
\modulus{(a+b)-(a_N+b_N)} &= \modulus{(a-a_N)+(b-b_N)}\\
&\leq \modulus{a-a_N}+\modulus{b-b_N}\\
&\leq \varepsilon/2 + \varepsilon/2\\
&= \varepsilon
\end{align*}
Therefore, we can use this $N$ to force the sum of the sequence elements to be within $\varepsilon$ of the sum of the limits.
\item Since both $a_n$ and $b_n$ converge to $a$ and $b$ respectively, we can find an $N$ such that all sequence members past $N$ in both sequences are within $\delta > 0$ of their limits. Knowing this, we'll want to estimate the distance between any two terms in the product sequence and the product of the limits whenever $n>N$:
\begin{align*}
\modulus{ab-a_nb_n} &= \modulus{ab-a_nb+a_nb-a_nb_n}\\
&= \modulus{b(a-a_n)+a_n(b-b_n)}\\
&\leq \modulus{b}\modulus{a-a_n} + \modulus{a_n}\modulus{b-b_n}\\
&\leq \modulus{b}\delta + \modulus{a_n}\delta
\end{align*}
Since \hyperlink{Convergent Sequences are Bounded}{convergent sequences are bounded}, we can bound $\modulus{a_n}$ by some $M$:
\begin{align*}
&\leq \delta\left(\modulus{b}+M\right)
\end{align*}
Therefore, given any $\varepsilon > 0$, since we can force both sequences to be within $\frac{\varepsilon}{\modulus{b}+M}$ of their limits via some $N$, we can get the product $a_nb_n$ to be within $\varepsilon$ of $ab$.
\item Since $a_n$ converges to $a$, we can find an $N$ such that all sequence members past $N$ are within $\delta > 0$ of $a$. In addition, since none of the $a_n$ are zero and neither is the limit, there exists an $m$ such that $0 < m \leq \modulus{a_n}$. We know this because after some $N$, $\modulus{a_n-a}<\modulus{a}/2$. We can now calculate the following:
\begin{align*}
\modulus{a_n} &= \modulus{a-(a-a_n)}\\
&\geq \modulus{a} - \modulus{a-a_n}\\
&\geq \modulus{a}/2
\end{align*}
We can then pick $m = \operatorname{min}{\left\{\modulus{a_0}, \modulus{a_1}... \modulus{a_N}, \modulus{a}/2\right\}}$. We can now bound the difference between the reciprocal of the limit and the reciprocal of any sequence element past $N$:
\begin{align*}
\modulus{\frac{1}{a}-\frac{1}{a_n}} &= \modulus{\frac{a_n-a}{aa_n}}\\
&= \frac{\modulus{a-a_n}}{\modulus{a}{\modulus{a_n}}}\\
&\leq \frac{\delta}{\modulus{a_n}\modulus{a}}\\
&\leq \frac{\delta}{m\modulus{a}}
\end{align*}
Therefore, given any $\varepsilon > 0$, finding an $N$ that forces $a_n$ to be within $m\modulus{a}\varepsilon$ of $a$ will force the reciprocal of $a_n$ to be within $\varepsilon$ of the reciprocal of $a$.
\item If $\modulus{a-a_n} < \varepsilon$, then $\modulus{\rpart{a}-\rpart{a_n}} = \modulus{\rpart{a-a_n}} \leq \modulus{a-a_n} < \varepsilon$. The same logic shows the equivalent condition for the imaginary part.
\item If $\modulus{a-a_n} < \varepsilon$, then $\modulus{\modulus{a}-\modulus{a_n}} \leq \modulus{a-a_n} < \varepsilon$.
\end{enumerate}
\end{proof}
\begin{definition}[Subsequence]
Suppose $\seq{a}$ is some sequence, and let $\seq{n}[k]\in \mathbb{N}$ be a sequence of naturals. If the sequence of naturals is \emph{increasing}, then the composition of the sequences $\seq{a}[n_k][k]$ is referred to as a \emph{subsequence} of $\seq{a}$.
\end{definition}
\begin{lemma}[Increasing Natural Sequences]
If $\seq{n}[k] \in \mathbb{N}$ is an increasing sequence, then $n_k \geq k$ for all sequence members.
\end{lemma}
\begin{proof}
We will prove this via induction. For the base case, since $n_0 \in \mathbb{N}$, then $n_0 \geq 0$. Now, assume that $n_k \geq k$. Since $n_{k+1} > n_k$, $n_{k+1} > k$. But since $n_{k+1}$ is a natural number, this means $n_{k+1} \geq k+1$. This completes the proof.
\end{proof}
\begin{theorem}[Convergent Subsequence Theorem]
If $\seq{a} \to a$, then any subsequence $\seq{a}[n_k][k] \to a$.
\end{theorem}
\begin{proof}
Since $\seq{a} \to a$, for any $\varepsilon > 0$ there exists a corresponding cuttoff $N$ which is valid for all sequence members past $N$. That is, if $k > N$, then $a_k$ is within $\varepsilon$ of the limit. However, we know that $n_k \geq k$, and therefore $n_N \geq N$. Thus, if $k > n_N$, then $k > N$. We therefore have a corresponding cutoff for the subsequence, namely $n_N$, after which all points are within $\varepsilon$ of the limit.
\end{proof}
\begin{theorem}[Sequences and Accumulation Points]
\begin{enumerate}
\item If $\seq{a} \in S$ and the sequence converges to $a$, then $a \in \overline{S}$.
\item If $a \in \overline{S}$ then there is some $\seq{a} \in S$ which converges to $a$.
\end{enumerate}
\end{theorem}
\begin{proof}
\begin{enumerate}
\item If $a$ is the topological limit of $\seq{a}$ then for every neighborhood of $a$ there exists some cuttoff $N$ such that all sequence members past $N$ are in the neighborhood. That is, for all $U \in \nbhd{a}$ the intersection $U \cap \{a_n\}$ is nonempty, and so is $U \cap S$. Therefore, $a$ is an accumulation point of $S$, and therefore is in $\overline{S}$.
\item Consider the sequence of disks $D_n = \disk{a}{2^{-n}}$. For each natural number $n$, we pick an $a_n \in D_n$. This sequence converges to $a$ because for every $\varepsilon > 0$ we can find the corresponding $N$:
\begin{align*}
2^{-N} &\leq \varepsilon\\
N &\geq -\log_2 (\varepsilon) 
\end{align*}
We can simply pick $N$ as some integer bigger than the right hand side thanks to the \hyperlink{Archimedean Property}{\emph{archimedean property of reals}}, which we prove in the next section.
\end{enumerate}
\end{proof}
\subsubsection{Sequences and the Topology of $\R$ and $\C$}
Now that we know the basics of sequences, we will use sequences to prove important properties of the topologies of the real and complex number systems. Doing so will require us to be a bit more explicit about what we mean by a ``real number." In this textbook, we will assume the defining property of the real numbers is the \emph{least upper bound property}, which states that any set of reals which is bounded from above has a least upper bound. Explicitly constructing the reals is beyond the scope of this book, but the interested reader can refer to any textbook on real analysis for more information.
\begin{lemma}[Archimedean Property]
Given any real number, there is some natural greater than it.
\end{lemma}
\begin{proof}
Assume for contradiction that there exists a real number which has no natural upper bound. Then this real number is an upper bound on the naturals. By the least upper bound property, this means there exists a supremum of all natural numbers, which we'll call $\alpha$. Since $\alpha$ is the \emph{least} upper bound, $\alpha -1$ is not an upper bound, and therefore there exists a natural number $n > \alpha -1$. Rearranging, we get $\alpha < n+1$. But since the right hand side is a natural, we've found a natural larger than the least upper bound on all natural numbers, leading to a contradiction.
\end{proof}
Note: The previous proof was an example of a proof method which we call "continuous induction". It allows us to prove statements for a large class of subsets of the reals in a manner similar to induction on the natural numbers. It will show up in future proofs.
\begin{theorem}[Density of Rationals in Reals]
If $S \subseteq \R$ is open, then it contains at least one member of $\mathbb{Q}$.
\end{theorem}
\begin{proof}
Choose $p \in S$. If $p \in \mathbb{Q}$, then we're done. If this is not the case, we'll need to do some more work. We'll assume for now that $p > 0$. If $p=0$, then $p$ is rational, and if $p < 0$, we can reflect the set across zero, find a rational point via the following method, and use the negative of that number as our rational. Since $S$ is open, there exists some $(p-\varepsilon, p+\varepsilon) \subseteq S$. Without loss of generality, we can assume $\varepsilon < p$, so that everything stays positive. We want to show that there exist integers $m, n$ such that $p-\varepsilon < \frac{m}{n} < p+\varepsilon$. We can define $n$ by the \hyperlink{Archimedean Property}{Archimedean Property} such that $n > \frac{1}{2\varepsilon}$. This will ensure that $\frac{1}{n} < 2\epsilon$. Again because of the \hyperlink{Archimedean Property}{Archimedean Property}, we can choose an $m$ such that $m-1 \leq n(p-\varepsilon) < m$. This number must exist, since the set of all integer upper bounds has a greatest lower bound which is an integer, and that integer minus one is not an upper bound.
From that equation, we can see that $p-\varepsilon < \frac{m}{n}$. We can also show that $p + \varepsilon > \frac{m}{n}$, since $p+\varepsilon = (p-\varepsilon)+ 2\varepsilon > \frac{1}{n}+\left(\frac{m}{n}-\frac{1}{n}\right) = \frac{m}{n}$. Thus, $\frac{m}{n}$ is in the open interval, and therefore in the set $S$.
\end{proof}
\begin{definition}[Dense Subset]
A set $S$ is called a \emph{dense subset} of a set $X$ if $S \subseteq X$ and $\overline{S} \cap X = X$. We write this as $S \stackrel{d}{\subseteq} X$.
\end{definition}
Our previous theorem showed that the rationals are dense in the reals because proof demonstrated that every open set, which is a neighborhood of any one of its points, contains a rational number. Thus, all of the points are limit points of the rationals, and are therefore included in the closure.
\begin{theorem}[Density of Gaussian Rationals in Complex Plane]
The \emph{Gaussian Rationals}, or complex numbers with rational coordinates, form a dense subset of the entire complex plane. (The Gaussian Rationals are often written $\mathbb{Q} [i]$)
\end{theorem}
\begin{proof}
We'll prove this the same way we proved the rationals are dense in the reals: by showing every open set in the complex plane contains a Gaussian rational. Let $S$ be such an open set, and pick $p \in S$. If $p$ is a Gaussian rational, we are done. Otherwise, we know since $S$ is open there exists a $\disk{p}{r} \subseteq S$. The disk contains all points of the form $x+iy$ where $(x-\rpart{p})^2+(y-\ipart{p})^2 < r^2$. Because \hyperlink{Density of Rationals in Reals}{the rationals are dense in the reals}, we can pick a rational $y$ such that $\modulus{y-\ipart{p}} < r$. This means that $(y-\ipart{p})^2 < r^2$, and therefore $r^2-(y-\ipart{p})^2$ is positive. If we look back on our original equation, we can see that all we need to do is find a rational $x$ which satisfies $\modulus{x-\rpart{p}} < \sqrt{r^2-(y-\ipart{p})^2}$. We can do this since the RHS is positive and \hyperlink{Density of Rationals in Reals}{the rationals are dense in the reals}.
\end{proof}
\\\\One interesting note is that in both the real and complex case, we were able to find a dense subset that was \emph{countable}. Proving the countability of $\mathbb{Q} [i]$ is not difficult, and is essentially the same proof as showing that the rationals themselves are countable. Sets like the reals and complex numbers with countable, dense subsets  have some important properties, so topologists have decided to give them a name:
\begin{definition}[Separable Space]
A topological space is called \emph{separable} if it contains a countable, dense subset.
\end{definition}
While we won't use the notion of separability much in this textbook, as we are not very interested in general topology, there is one important lemma that is true in all separable spaces.
\begin{lemma}[Disjoint Open Sets Lemma]
Suppose $X$ is a separable topological space, and let $\mathcal{F}$ be a family of open sets in $X$ which are \emph{pairwise disjoint}. Then $\mathcal{F}$ contains countably many subsets.
\end{lemma}
\begin{proof}
Since $X$ is separable, there is a countable, dense subset, which we'll call $Y$. Since $Y$ is dense in $X$, every open set in $X$ contains at least one member of $Y$. We can therefore define a mapping $g: \mathcal{F} \to Y$ by picking a point in $Y$ from every open set in $\mathcal{F}$: $g(U) \in U \cap Y$. Note that this mapping must be one-to-one, since if $g(U)=g(V)$ that must mean that the sets overlap, which is impossible because the open sets are pairwise disjoint. Since we have a one-to-one mapping from $\mathcal{F}$ to a countable set, this means that $\mathcal{F}$ itself is countable.
\end{proof}
\begin{theorem}[Nested Intervals Theorem]
Suppose $\seq{I}$ is a sequence of \emph{closed intervals} which are \emph{downward nested}. That is, $I_n \supseteq I_{n+1}$. Then there exists some $s \in \R$ which is in every $I_n$.
\end{theorem}
\begin{proof}
Let $I_n = [a_n,b_n]$. The nesting condition implies that the $a_n \leq a_{n+1}$, $b_{m+1} \leq b_m$, and $a_n \leq b_m$ for all $m$ and $n$. Let $A = {a_n}$ and $B = {b_n}$. Since $A$ is bounded from above, it has a supremum, which we'll call $s$. Each $b_n$ is an upper bound of $A$, but $s$ is the least upper bound, so $a_n \leq s \leq b_n$. Therefore, $s \in I_n$ for all $n$.
\end{proof}
\begin{corollary}[Collapsing Intervals Lemma]
If the length of each interval (the distance between the endpoints) is a sequence converging to $0$, then there is a \emph{unique} point which is in every interval.
\end{corollary}
\begin{proof}
We know by the \hyperlink{Nested Intervals Theorem}{original theorem} that there at least \emph{exists} some point $s$  which is in every interval. Now let $\tilde{s} \in \R$ be any other point. We will now show that if the intervals are not just nested, but \emph{collapsing}, $\tilde{s}$ can't be in every interval. Let $\epsilon = \modulus{s-\tilde{s}}$. Note that the maximum distance between any two points in $I_n$ is $d_n = \modulus{a_n-b_n}$. Therefore, since $s \in I_n$, $I_n \subseteq [s-d_n,s+d_n]$. However, $d_n$ can be made as small as we want, since the intervals are collapsing. There is, therefore some $N$ such that $d_N < \epsilon$. If this is the case, then $\tilde{s}$ is not in the larger interval $[s-d_N,s+d_N]$, and therefore isn't in $I_N$. Therefore, there's only one point which is in every interval.
\end{proof}
\begin{theorem}[Monotone Sequence Theorem]
Suppose $\seq{a} \in \R$ is \emph{monotonically increasing}. That is, suppose $a_{n+1} \geq a_n$. If $\seq{a}$ is \emph{bounded}, then the sequence converges to the least upper bound of all of its elements.
\end{theorem}
\begin{proof}
Since the sequence $\seq{a}$ is bounded, then by the least upper bound property it has a supremum, $a$. Since $a$ is the smallest such upper bound, for any $\varepsilon > 0$, $a-\varepsilon$ is not an upper bound of $\seq{a}$. Therefore, there is some $a_n$ such that $a-\varepsilon < a_n \leq a$. Since the sequence is monotonically increasing, this double inequality is true of any $a_k$ where $k \geq n$. Since $\varepsilon > 0$, we can rewrite this as $a-\varepsilon < a_k < a+\varepsilon$ for all $a_k$ where $k$ is sufficiently large. But we can write this inequality as $\modulus{a-a_k} < \varepsilon$, showing the sequence converges to $a$.
\end{proof}
\begin{theorem}[Squeeze Theorem]
If $\seq{a},\seq{b},\seq{c} \in \R$ and $a_n \leq b_n \leq c_n$ and $\seq{a}, \seq{c} \to L$ then $\seq{b} \to L$.
\end{theorem}
\begin{proof}
Since both the left and right sequences converge to $L$, given any $\varepsilon > 0$, we can find a common cutoff such that both $a_n$ and $c_n$ are within $\varepsilon$ of the limit. This means that $L-\varepsilon < a_n$ and $c_n < L+\varepsilon$. But because of the inequality, this tells us that $L-\varepsilon < b_n < L+\varepsilon$, and therefore $\modulus{b_n - L} < \varepsilon$, completing the proof.
\end{proof}
\begin{theorem}[Bolzano-Weierstrass Theorem, Real-Valued Case]
Suppose $\seq{a} \in \R$ is a bounded sequence. Then there exists a subsequence $\seq{a}[n_k][k]$ which is convergent. 
\end{theorem}
\begin{proof}
We will prove this via the \hyperlink{Collapsing Intervals Lemma}{collapsing intervals lemma}. Since the sequence is bounded, we know there exists an $M$ such that $\modulus{a_n} \leq M$. We'll let $I_0 = [-M, M]$. Since $\seq{a} \in I_0$, the interval contains infinitely many terms in the sequence. We will want to construct our interval sequence in such a way that each interval contains infinitely many terms. Suppose $I_n = [l, r]$ does contain infinitely many terms. If the interval $[l, \frac{l+r}{2}]$ contains infinitely many terms, we'll let that be the $I_{n+1}$. Otherwise, the interval $[\frac{l+r}{2}, r]$ will contain infinitely many terms of the sequence, and we'll choose it to be our $I_{n+1}$. Clearly, $I_{n+1} \subseteq I_n$, so we do have a sequence of nested intervals. In addition, since each interval is half the length of the previous, the intervals are collapsing, which we know means there exists exactly one real number in all of them. We'll call this number $\tilde{a}$. Now we'll define a subsequence that converges to $\tilde{a}$.
First, choose an arbitrary sequence member and call it $a_{n_0}$. To get $a_{n_k}$, we'll pick any sequence member $a_q$ in $I_k$ such that $q > n_{k-1}$. This way, the $n_k$ form an increasing sequence of naturals. We can always find such a sequence member because each interval contains infinitely many sequence members to choose from. Now since $a_{n_k}$ and $\tilde{a}$ are both in $I_k$. Since the length of the intervals keeps getting smaller, we can say $0 \leq \modulus{a_{n_k} - \tilde{a}} \leq \frac{M}{2^k}$. Since the length goes to zero, the distance between the subsequence terms and $\tilde{a}$ goes to zero, and therefore $a_{n_k}$ goes to $\tilde{a}$.
\end{proof}
The previous theorem can easily be generalized to the complex numbers:
\begin{theorem}[Bolzano-Weierstrass Theorem]
Suppose $\seq{a} \in \C$ is a bounded sequence. Then there exists a subsequence $\seq{a}[n_k][k]$ which is convergent. 
\end{theorem}
\begin{proof}
Since $\seq{a}$ is bounded, then $\modulus{a_n} \leq M$ for some bound. This also means that $\modulus{\rpart{a_n}} \leq M$. We can apply the \hyperlink{Bolzano-Weierstrass Theorem, Real-Valued Case}{Bolzano-Weierstrass for reals} to this sequence and get a convergent subsequence of reals. If we use these indices on our original, complex-valued sequence, we obtain a second sequence, $\seq{b}$. Now we can use the same logic on the $b_n$ to find a subsequence $\seq{c}$ which has convergent \emph{imaginary} parts. Since the imaginary parts converge, and the real parts converge since they are a subsequence of the convergent real parts of $\seq{b}$, we have found a convergent subsequence of $\seq{a}$.
\end{proof}
The proof of the previous theorems relied implictly on a small lemma, which we'll prove here in its most general form
\begin{lemma}[Subsequences and Accumulation Points]
If a sequence has an accumulation point which is not a member of the sequence then there is a subsequence converging to that accumulation point.
\end{lemma}
\begin{proof}
Let $\seq{a} \in \C$ be some sequence, and let $\tilde{a}$ be an accumulation point which doesn't appear within the sequence. We'll define a sequence of disks $D_n = \disk{\tilde{a}}{2^{-n}}$. These form a nested sequence of disks: $D_0 \supseteq D_1 \supseteq D_2 \ldots$ Now we'll show that each disk contains infinitely many sequence members. Assume for the sake of contradiction that some $D_n$ contains only finitely many sequence members. Since none of these sequence members are equal to $\tilde{a}$, they are all some positve distance away from it. We can take the minimum distance, which we'll call $\varepsilon$, and look at $D_M$, where $M \geq \log_2 (\varepsilon)$. This disk has a radius less than or equal to $\varepsilon$, so it does not contain any sequence members. But this would contradict $\tilde{a}$ being an accumulation point.\\
Now that we've established that each disk contains infinitely many elements, we can begin constructing a subsequence. Let $n_0$ be the first index where $a_{n_0} \in D_0$. Given $n_k$, we'll define $n_{k+1}$ as the first index greater than $n_k$ such that $a_{n_{k+1}} \in D_{k+1}$. We can pick such an element since $D_{k+1}$ has infinitely many sequence members, and requiring that $n_{k+1} > n_k$ only gets rid of finitely many sequence members. This gives us a subsequence $\seq{a}[n_k][k] \in \C$ such that $a_{n_k} \in D_k$. Therefore $\modulus{\tilde{a}-a_{n_k}} < \frac{1}{2^k}$. Since the right hand side can be made as small as we want, so can the left hand side. Therefore, the subsequence converges to $\tilde{a}$. 
\end{proof}
\subsubsection{Cauchy Sequences and Completeness}
\begin{definition}[Cauchy Sequence]
A sequence $\seq{a}$ is called \emph{Cauchy} iff for every $\varepsilon > 0$ there exists some natural number $N$ such that $m, n > N \implies \modulus{a_m-a_n} < \varepsilon$.
\end{definition}
\begin{lemma}[Convergent Sequences are Cauchy]
If $\seq{a}$ is convergent, then it is Cauchy.
\end{lemma}
\begin{proof}
Since the sequence is convergent, for every $\varepsilon > 0$, there is a corresponding cuttoff such that all members past the cutoff are within $\varepsilon$ of the limit, $a$. Pick some $\delta > 0$ and pick any two sequence members beyond the cutoff. We can now calculate the distance betweeen them:
\begin{align*}
\modulus{a_n-a_m} &= \modulus{(a_n -a) - (a_m-a)}\\
&\leq \modulus{a_n - a} + \modulus{a_m - a}\\
&\leq 2\delta
\end{align*}
This is enough to show our sequence is Cauchy. Given any $\varepsilon > 0$, we pick the cutoff that gets sequence members within $\varepsilon/2$ of the limit, which will get them within $\varepsilon$ of each other.
\end{proof}
\begin{lemma}[Cauchy Sequences are Bounded]
If $\seq{a}$ is Cauchy, then it is bounded.
\end{lemma}
\begin{proof}
Since $\seq{a}$ is Cauchy, we can pick a positive $\varepsilon$ and get a cutoff such that $\modulus{a_n-a_m} < \varepsilon$. If we fix $a_n$, we get that the set of all sequence members past the cutoff is bounded. Since the set of all members before the cutoff is finite, and therefore also bounded, we get that the whole sequence is bounded.
\end{proof}
\begin{definition}[Completeness]
A set $X$ with a metric defined on it is called \emph{complete} if every Cauchy sequence in the set converges to a point in the set.
\end{definition}
\begin{theorem}[Completeness of $\C$]
The set of all complex numbers,  $\C$, is complete.
\end{theorem}
\begin{proof}
Take any Cauchy sequence $\seq{a}$. Because \hyperlink{Cauchy Sequences are Bounded}{Cauchy sequences are bounded}, we can apply the \hyperlink{Bolzano-Weierstrass Theorem}{Bolzano-Weierstrass theorem} and find a convergent subsequence, $\seq{a}[n_k][k]$. This sequence converges to a complex number, $a$. Now we want to show that our original sequence converges to $a$ as well.
Since our original sequence is Cauchy, there exists a cutoff after which $\modulus{a_n-a_m} < \varepsilon/2$ for any positive $\varepsilon$. Since the subsequence converges to $a$, we can find a cutoff after which $\modulus{a-a_{n_k}} < \varepsilon/2$. Now, consider the maximum of these two cutoffs, $N$. If we let $n> N$ and $n_k>N$, we can calculate the following: 
\begin{align*}
\modulus{a_n - a} &\leq \modulus{a_n-a_{n_k}} + \modulus{a_{n_k}-a}\\ &\leq \varepsilon/2 +\varepsilon/2\\ &= \varepsilon
\end{align*}
Thus, we can make the original sequence as close as we want to the limit of the subsequence by choosing a sufficiently large cutoff.
\end{proof}
\begin{theorem}[Closed Subsets of Complete Sets are Complete]
If $X$ is complete, and $Y \subseteq X$ and $Y$ is closed, $Y$ is complete.
\end{theorem}
\begin{proof}
Suppose $\seq{a} \in Y$ is a Cauchy sequence. Since $Y \subseteq X$, it is also a Cauchy sequence in $X$, and since $X$ is complete, it converges to $a \in X$. However, since $\seq{a}$ is a sequence in $Y$ and $Y$ is closed, the sequence must converge to a point in $Y$ if it converges at all. Therefore, $a \in Y$, showing that $Y$ is complete.
\end{proof}
\subsection{Connectedness and Compactness}
The notions of \emph{connectedness} and \emph{compactness} are somewhat subtle topological concepts, but they are extremely useful in proofs. Fortunately, they are much easier to understand in the real or complex numbers then they are in more pathological topological spaces. We'll start with connectedness, as it's the easier of the two to understand.
\subsubsection{Connectedness}
\begin{definition}[Connected Set]
A set $X \subseteq \C$ is called \emph{connected} if there do not exist two sets $A$ and $B$ with the following properties:
\begin{enumerate}
\item $A$ and $B$ are open \emph{relative to} $X$.
\item Neither $A$ nor $B$ are empty.
\item $A \cap B = \emptyset$.
\item $A \cup B = X$.
\end{enumerate}
In other words, $X$ is connected if it is not the union of two nonempty, disjoint, relatively open sets. We'll often abbreviated this by saying that connected sets cannot be partitioned ``nontrivially" into relatively open sets. We can think of connected sets as sets which ``come in one piece."
\end{definition}
\begin{lemma}[Alternate Definitions for Connected Sets]
Replacing ``relatively open" with ``relatively closed" in the definition of a connected set yields an equivalent definition. In addition, a set $U$ is connected iff there does not exist a subset of $U$ which is relatively \emph{clopen} (both closed and open) other than $U$ or the empty set.
\end{lemma}
\begin{proof}
We'll quickly demonstrate that the relative complement of a relatively closed set is open: If $K$ is closed relative to $U$, then $K = U \cap \tilde{K}$ for some closed set $\tilde{K}$. Since $\tilde{K}$ is closed, $\tilde{K}^C$ is open. $U \setminus \tilde{K} = U \cap \tilde{K}^C$, which is the intersection of $\tilde{K}^C$, an open set, with $U$, and is therefore open relative to $U$. The same logic shows that the reverse is also true: the relative complement of a relatively closed set is relatively closed.\\
To show that the two new definitions of connectedness are equivalent to our original definition, we'll instead show that they give the same notion of what it means for a set to be \emph{disconnected}, i.e. not connected. Suppose $V$ is disconnected via our original definition. Then it can be nontrivially decomposed into disjoint relatively open sets: $V = A \cup B$. Since $B$ is open relative to $V$, $V \setminus B$ is closed relative to $B$. But since $A$ and $B$ are disjoint and their union is exactly $V$, $V \setminus B = A$. Thus, we've found a nontrivial relatively clopen set. Likewise, if we have a nontrival relatively clopen set, its complement will be relatively open, and we've found a nontrivial decomposition into relatively open sets. The same reasoning shows that a nontrivial decomposition into relatively closed sets is equivalent to the exsitence of a nontrivial relatively clopen set. Thus, all definitions agree on what constitutes a disconnected set, so they must agree on what doesn't constitute a disconnected set, i.e. what constitutes a connected set.
\end{proof}
\begin{lemma}[Connected Subsets of Reals]
A subset of $\R$ is connected iff it is some sort of interval (open, closed, half-open).
\end{lemma}
\begin{proof}
We'll first prove that if a subset of the reals $E$ is connected, then it is an interval. Since $E$ is a subset of $\R$, it has an infimum and a supremum, although the infimum may be $-\infty$ and the supremum may be $\infty$. Any point $p \in E$ is greater than or equal to the supremum and less than or equal to the infimum. Suppose there exists some point $p$ which is strictly between the infimum and the supremum that is not in the set $E$. Then we can write $E$ as the union of two relatively open sets: $(-\infty, p) \cap E$ and $(p, \infty) \cap E$ have a union of $(\R \setminus \{p\}) \cap E = E$. Because $E$ is connected, one of these sets must be empty. If the left set is empty, then there are no points in $E$ less than $p$, meaning $p$ is a lower bound. But this contradicts the assumption that $p$ was strictly greater than the infimum. Similarly, the right hand set cannot be empty, so $E$ contains all points between its infimum and supremum, making it an interval.\\
Now for the converse. Suppose $I$ is an interval of some sort, and assume for the sake of contradiction it can be written as $A \cup B$, where $A$ and $B$ are disjoint, nonempty, and relatively closed. Since they are relatively closed, we can write them as intersections of the interval with closed sets: $A = \tilde{A} \cap I, B = \tilde{B} \cap I$. Pick some points $a_0 \in A$ and $b_0 \in B$. Since the sets are disjoint, we can assume without loss of generality that $a_0 < b_0$. We will now turn this pair of points into a sequence of collapsing intervals. We are given the closed interval $[a_n, b_n]$ where $a_n \in A$ and $b_n \in B$ and want to find $[a_{n+1}, b_{n+1}]$. To do this, we bisect our given interval. The midpoint is either in $A$ or $B$. Since one of the endpoints is in $A$ and the other in $B$, we pick whichever of the two intervals has a left endpoint in $A$ and a right endpoint in $B$. By the \hyperlink{Collapsing Intervals Lemma}{collapsing intervals lemma}, there is exactly one point in all of these intervals, which we'll call $c$, which satisfies $a_n \leq c \leq b_n$ for all $n$. Because the intervals are collapsing, the $a_n$ form a monotonically increasing sequence. The supremum of all the $a_n$ must be $c$, because if there were a smaller lower bound, it would appear in the intersection of the intervals. Therefore, by the \hyperlink{Monotone Sequence Theorem}{monotone sequence theorem}, $a_n \to c$. Similar logic shows that $b_n \to c$. But since \hyperlink{Sequences and Accumulation Points}{$\tilde{A}$ and $\tilde{B}$ are closed}, $c$ is in both $\tilde{A}$ and $\tilde{B}$. But because $c$ is between two points in the interval, it is in the interval, and therefore in $A\cap B$. This contradicts our assumption that $A$ and $B$ were disjoint, so the interval must be connected. 
\end{proof}
\begin{definition}[Region]
A set $X \subseteq \C$ is called a \emph{region} if it is nonempty, connected, and open. This is written $\region{U}$.
\end{definition}
\begin{theorem}[Fundamental Theorem of Regions]
Suppose we have an equivalence relation $\sim$ between points in a region $\region{U}$. Suppose this equivalence relation also has the property that if $\disk{a}{\epsilon} \subseteq U$ then for all $z \in \disk{a}{\epsilon}, z\sim a$. Then for any two points $p,q \in U, p\sim q$.
\end{theorem}
\begin{proof}
Since $U$ is a region, it is nonempty. We can therefore pick some $p \in U$. We'll now partition the region into two subsets as follows: let $A$ be the subset of $U$ consisting of all points equivalent to $p$, and let $B = U \setminus A$. Clearly these sets are disjoint, and their union is $U$. Now we will prove that both $A$ and $B$ are open.
If $A$ is empty, then by definition it is open. If it is not empty, we can pick some point $a \in A$. Now because $U$ is open, there exists a $\disk{a}{\epsilon} \subseteq U$. Now pick any $z$ in that disk. We know that since $a$ is in $A$, $a \sim p$. However, we know by assumption that if there is a disk in $U$, all points in the disk are equivalent to the center of the disk. That is, $z \sim a$, and by transitivity, $z \sim p$. Therefore, all points in the disk are equivalent to $p$, and are therefore in $A$. Since for any $a \in A$, we now know that there exists a disk centered at $a$ in $A$, $A$ is a neighborhood of all of its points and therefore is open.
We will proceed similarly with B. If $B$ is empty, then by definition it is open. If it is not empty, we can pick some point $b \in B$. Now because $U$ is open, there exists a $\disk{b}{\epsilon} \subseteq U$. Now pick any $z$ in that disk. We know that since $b$ is in $B$, $b \not\sim p$. However, we know by assumption that if there is a disk in $U$, all points in the disk are equivalent to the center of the disk. If any point in the disk were equivalent to $p$, by transitivity that would force the center of the disk ot be equivalent to $p$, which contradicts our assumption that the center of the disk is in $B$. That is, $z \sim b$, and by transitivity, $z \not\sim p$. Therefore, all points in the disk are \emph{not} equivalent to $p$, and are therefore in $B$. Since for any $b \in B$, we now know that there exists a disk centered at $b$ in $B$, $B$ is a neighborhood of all of its points and therefore is open.\\
We've found a decomposition of $U$ into disjoint open sets. These sets are also open relative to $U$, since they are subsets of $U$ and therefore equal to their own intersections with $U$. By the definition of connectedness, the only way this could happen is if one of the sets is empty. We know that $A$ is nonempty because $p \sim p$, so $B$ must be the empty one. But this means that $A=U$, so any point in $U$ is equivalent to $p$. But if $a,b \in U$ are both equivalent to $p$, then by transitivity $a \sim b$.
\end{proof}
\begin{definition}[Connected Component]
A connected subset $C \subseteq X$ is called an \emph{connected component} of $X$ if there does not exist another connected subset of $X$ such that $C$ is a proper subset of that connected subset.
\end{definition}
\begin{theorem}[Connected Components Theorem]
Every set has a unique decomposition into connected components.
\end{theorem}
\begin{proof}
Let $X$ be any set, and pick some $a \in X$. Define $C_X(a)$ as the union of all connected subsets of $X$ which contain the point $a$. We will shortly prove that for any point, this union is a connected set. If this is the case, we can easily show that this set is a connected component, and that two connected components are either disjoint or identical. Firstly, suppose there was some connected subset of $X$ such that $C_X(a)$ was a proper subset of that connected subset. If it was, then this connected subset would contain $a$, and therefore be in the union of all connected subsets containing $a$. This means that $C_X(a)$ couldn't possibly be a proper subset of any larger connected subset, and it therefore must be a component. Now we'll show that the distinct components are disjoint. Suppose there exists a $c$ which is in $C_X(a) \cap C_X(b)$. Since $C_X(a)$ is a connected subset of $X$ containing $c$, $C_X(a) \subseteq C_X(c)$. This means that $a$ is in $C_X(c)$, and by the same logic $C_X(c) \subseteq C_X(a)$, and therefore $C_X(c)=C_X(a)$. The same reasoning shows that $C_X(c) = C_X(b)$, and therefore $C_X(a) = C_X(b)$. Thus, two components which are not disjoint turn out to be identical.\\
For the previous logic to hold, we need to show that the $C_X$ sets are actually connected. Suppose there exists an $a \in X$ such that $C_X(a)$ is disconnected. Then there exist relatively open nonempty sets $A, B$ whose union is $C_X(a)$ and whose intersection is $\emptyset$. Without loss of generality, let $a \in A$. Since $B$ is nonempty, there exists a $b \in B$. Since $b \in C_X(a)$ and $C_X(a)$ is the union of all connected subsets of $X$ containing $A$, there exists a connected subset of $X$ called $X_0$ such that $a, b \in X_0$. However, we know that $X_0 = (X_0 \cap A) \cup (X_0 \cap B)$ since $X_0$ is a subset of $C_X(a)$. Since $A$ and $B$ are open relative to $C_X(a)$ and $X_0 \subseteq C_X(a)$, the sets $X_0 \cap A$ and $X_0 \cap B$ are relatively open. They are also disjoint since $A$ and $B$ are disjoint. Since $a \in X_0 \cap A$ and $b \in X_0 \cap B$, these sets are nonempty. This contradicts the connectedness of $X_0$. Therefore, $C_X(a)$ has to be connected.
\end{proof}
\subsubsection{Compactness and Sequential Compactness}
There are two separate, but deeply connected notions of what it means for a set to be \emph{compact}: compactness and sequential compactness. Both of these are generalizations of the notion of a closed and bounded set. One of the most important facts about the topology of $\R^n$ and $\C^n$ is that these notions are all equivalent, which is formalized in the famous \emph{Heine-Borel Theorem}. We'll start with sequential compactness, as it's easier to understand.
\begin{definition}[Sequential Compactness]
A set $X$ is called \emph{sequentially compact} if for every $\seq{a} \in X$ there exists a subsequence $\seq{a}[n_k][k] \in X$ which converges to a point in $X$.
\end{definition}
\begin{theorem}[Sequential Compactness Theorem]
A set $X \subseteq \C$ is sequentially compact iff it is closed and bounded.
\end{theorem}
\begin{proof}
First, we'll show that sequentially compact sets are closed and bounded. If $X$ is not closed, then it's missing at least one limit point. We can simply pick a sequence in $X$ that converges to this limit point, and we've found a sequence that does not have a subsequence which converges to a point in $X$. Similarly, suppose $X$ was unbounded. We can then pick a sequence such that $\modulus{a_n} > n$. We can see this sequence is not Cauchy: $\modulus{a_{n+1}-a_n} \geq \modulus{a_{n+1}}-\modulus{a_n} > 1$. Since \hyperlink{Convergent Sequences are Cauchy}{every convergent sequence must be Cauchy}, this sequence does not converge.\\
Now for the converse. Suppose $X$ is closed and bounded, and let $\seq{a} \in X$ be an arbitrary sequence. Since the set $X$ is bounded, so is the sequence, so by \hyperlink{Bolzano-Weierstrass Theorem}{Bolzano-Weierstrass}, there exists a convergent subsequence. But since $X$ is closed, any sequence in $X$ that converges must converge to a point in $X$. Therefore the subsequence converges to a point in $X$, and the set is therefore sequentially compact.
\end{proof}
\begin{definition}[Open Cover]
If $X$ is some set, an \emph{open cover} of $X$ is a collection of open sets relative to $X$ whose union is a superset of $X$.
\end{definition}
\begin{lemma}[Alternate Definition for Open Covers]
If $X$ is covered by (in the union of) a collection of open sets, then we can intersect each open set with $X$ to get a collection of open sets relative to $X$ whose union is $X$, i.e. an open cover by our original definition.
\end{lemma}
\begin{definition}[Subcover]
If $C$ is an open cover of $X$, then a \emph{subcover} of $C$ is some subset $F \subseteq C$ which is still an open cover of $X$.
\end{definition}
\begin{definition}[Compactness]
A set $X$ is called compact if for every open cover of $X$ there exists a subcover which contains \emph{finitely many sets}.
\end{definition}
\begin{lemma}[Closed Subsets of Compact Sets]
If $S \subseteq K$ where $S$ is closed and $K$ is compact, then $S$ is also compact.
\end{lemma}
\begin{proof}
Let $\mathcal{G}$ be an open cover of $S$. The open cover is made up of sets which are open relative to $S$, and are therefore the intersection of some open set with $S$. If we take any one of these open sets and instead intersect them with $K$, we'll get an open set relative to $K$ which contains the original open set relative to $S$. We can now construct an open cover of $K$, $\tilde{\mathcal{G}}$, which contains all of these new relative open sets as well as $K \setminus S$. This last set is open relative to $K$ because it can be written as $K \cap S^C$, and $S$ is closed, meaning $S^C$ is open. We know this covers $K$ since the original open cover modified so that the sets are open relative to $K$ instead of $S$ contains $S$ in its union, and we just add on another set which adds in any points we may have missed.\\
Now, since $K$ is compact, we can pick a finite subcover of $\tilde{\mathcal{G}}$. Since the union of all the sets in this subcover is $K$, the union contains $S$ as well. Since no point in $S$ is in $K\setminus S$, we still would have $S$ in the union of all sets in this finite subcover except for $K \setminus S$. Finally, since all of these sets are open relative to $K$, we can intersect them with $S$ to get a finite subcover of $S$. Therefore, $S$ is compact.
\end{proof}
\begin{theorem}[Heine-Borel Theorem]
A set $X \subseteq \C$ is compact iff it is closed and bounded.
\end{theorem}
\begin{proof}
First, we'll prove that compactness implies that the set is closed and bounded. By the \hyperlink{Sequential Compactness Theorem}{sequential compactness theorem}, we know that a set is closed and bounded iff it is sequentially compact. Thus, we can alternatively show that every compact set is sequentially compact. Assume for the sake of contradiction that there exists a $K \subseteq \C$ which is compact but not sequentially compact. If it is not sequentially compact, there exists a $\seq{a} \in K$ with no convergent subsequence. Pick any $z \in K$. Note that $z$ cannot be an accumulation point of the sequence, since if it were we could find a subsequence converging to $z$. Therefore, there exists a $\varepsilon_z$ such that $\disk{z}{\varepsilon_z}$ contains no points from the sequence except possibly $z$ itself. Now consider the collection of all of these disks for all $z \in K$. This is an open cover of $K$. Since each disk contains at most one sequence element, every finite subcollection of this open cover will contain only finitely many sequence elements. Therefore, this open cover cannot have a finite subcover, since any finite subcollection of our open cover doesn't contain all of the $a_n$, instead containing only finitely many of them. This is a contradiction, so every compact set must be sequentially comapct.\\
Now we'll show that closed and bounded sets are sequentially compact. By a \hyperlink{Closed Subsets of Compact Sets}{previous lemma}, we know that any closed subset of a compact set is compact. Suppose $S$ is a closed and bounded set. Since it is bounded, it can be put in a disk centered at zero. This disk can then be put inside a \emph{closed tile}, which is a set consisting of all points whose real parts are in some closed interval and whose imaginary parts are in some other closed interval. We'll call this tile $T_0$. If we can show that every closed tile is compact, we'll show that every closed and bounded set is compact. Assume for contradiction that $T_0$ is not compact. This means that some open cover of $T_0$ does not have a finite subcover. Bisect the tile both horizontally and vertically to get four subtiles. Our open cover of these four tiles cannot have a finite subcover for each of them, since that would mean we'd have a finite subcover for the whole tile. Let $T_1$ be any of the tiles that doesn't have a finite subcover. Now we continue this process creating a sequence of collapsing tiles $T_n \supset T_{n+1}$ with each tile not having a finite subcover. By the \hyperlink{Collapsing Intervals Lemma}{collapsing intervals lemma} applied to both the real and imaginary parts, there is exactly one complex number in every subtile. Call this point $\tilde{z}$. Now since $\tilde{z} \in T_0$, there must be an open set $U$ that is a member of the subcover and which contains $\tilde{z}$. Since $U$ is open, there is some $\disk{\tilde{z}}{\varepsilon} \subseteq U$. Since the boxes can be made arbitrarily small, eventually some $T_k$ will be completely inside this disk, which means it will be inside of $U$. But we said that $T_k$ had to be covered by infinitely many sets in the open cover, and yet we've found a single set in the open cover $U$ which will cover $T_k$. This is a contradiction, so the open cover must have a finite subcover. This means that every tile is compact, and therefore every closed and bounded set is compact.
\end{proof}
\begin{corollary}[Compact Subsets of the Reals]
Every compact subset $K \subseteq \R$ has a minimum and a maximum.
\end{corollary}
\begin{proof}
Since $K$ is compact, it's closed and bounded. Since it's bounded, it has a supremum, which we'll call $s$. Note that $s$ is a limit point of $K$ because if there were some open interval centered at $s$ which did not contain any point of $K$, we could find an upper bound of $K$ smaller than the supremum. But since $K$ is closed, $s \in K$. The same argument shows that the greatest lower bound is also in $K$.
\end{proof}
\begin{definition}[Distance Between Sets]
If $A, B \subseteq \C$ are two sets, the \emph{distance} between them is simply the infimum of the distances between $a \in A$ and $b \in B$.
\end{definition}
\begin{theorem}[Distance Between Compact and Closed Sets]
Suppose $A$ is a compact subset of $\C$ and $B$ is a closed subset of $\C$. If $A \cap B = \emptyset$, then the distance between the two sets is nonzero.
\end{theorem}
\begin{proof}
Suppose that we have a compact and closed set such that the distance between them is zero. Since the distance between two sets is the infimum of the distance between points in one set and points in the other set, we can always find a $A \in A$ and a $b \in B$ such that $\modulus{a-b} < \varepsilon$ for any $\varepsilon > 0$. If this were not the case, we'd have found a positive upper bound on the distances between pairs of points in the sets, and therefore the distance between the sets would be nonzero. Given this, we can pick sequences $\seq{a} \in a$ and $\seq{b} \in B$ such that $\modulus{a_n - b_n} < \frac{1}{2^n}$. By the \hyperlink{Squeeze Theorem}{squeeze theorem}, $\lim_{n\to\infty}\modulus{a_n -b_n} = 0$. Since $\seq{a}$ is a sequence in a compact set, by \hyperlink{Heine-Borel Theorem}{Heine-Borel} there exists a subsequence $\seq{a}[n_k][k]$ which converges to $a \in A$. We have:
\begin{align*}
\lim_{k\to\infty}\modulus{a-b_{n_k}} &\leq \lim_{k\to\infty}(\modulus{a-a_{n_k}} + \modulus{a_{n_k} - b_{n_k}})\\
&= \lim_{k\to\infty}\modulus{a-a_{n_k}} + \lim_{k\to\infty}\modulus{a_{n_k}-b_{n_k}}\\
&= 0
\end{align*}
Therefore, $a$ is an accumulation point of $B$, and since $B$ is closed, $a\in B$. Thus, the two sets aren't disjoint. If they were, the distance between them couldn't be zero.
\end{proof}
\subsection{Functions and Their Limits}
Here we will extend our concept of the limit of a sequence to a limit of a \emph{function}. First, we will examine the limiting behavior as functions tend towards a particular point in their domain, and then we will examine the different types of limits that exist for sequences of functions.
\subsubsection{Limits of Functions}
\begin{definition}[Topological Limit of a Function]
Suppose $\fn{f}{X}{Y}$ is a function between two sets which are both subsets of larger topological spaces. Suppose $p \in \overline{X}$. Then we write $\lim_{x \to p} f(x) = L$ iff for every neighborhood $V \in \nbhd{L}$ there exists a \emph{relatively punctured neighborhood} $U \in \rpnbhd{p}{X}$ such that $f[U] \subseteq V$.
\end{definition}
\begin{definition}[Sequential Limit of a Function]
Suppose $\fn{f}{X}{Y}$ is a function between two sets which are both subsets of larger topological spaces. Suppose $p \in \overline{X}$. Then we write $\lim_{x \to p} f(x) = L$ iff given any sequence $\seq{a} \in X\setminus \{p\}$ which converges to $p$ the sequence $b_n = f(a_n)$ converges to $L$.
\end{definition}
\begin{definition}[Metric Limit of a Function]
Suppose $\fn{f}{X\subseteq\C}{\C}$ is a function. Suppose $p \in \overline{X}$. Then we write $\lim_{x \to p} f(x) = L$ iff for every $\varepsilon > 0$ there exists a $\delta > 0$ such that $(x \in X) \land (0<\modulus{x-p}< \delta) \implies \modulus{f(x)-L} < \varepsilon$.
\end{definition}
\begin{theorem}[Equivalence of Limit Types for Functions]
If $\fn{f}{X\subseteq\C}{\C}$ is a function, then it has a topological limit of $L$ at $p \in \overline{X}$ iff it has a sequential limit of $L$ at $p \in \overline{X}$ iff it has a metric limit of $L$ at $p \in \overline{X}$.
\end{theorem}
\begin{proof}
\\(Topological $\implies$ Metric): Suppose $\lim_{x \to p} f(x) = L$ in the topological sense. We want to show it has a metric limit of $L$ as well. We are given a $\varepsilon$, and are tasked with finding the corresponding $\delta$. Since we know the function converges topolgoically, we can pick a neighborhood $V = \disk{L}{\varepsilon}$. We know there is a corresponding relatively punctured neighborhood $U$. Since $U$ is a punctured neighborhood relative to $X$, we can write it as $U = \tilde{U} \cap X$, where $\tilde{U}$ is a punctured neighborhood of $p$. Since $\tilde{U}$ is a punctured neighborhood of $p$, it contains some punctured disk $\pdisk{p}{\delta} \subseteq \tilde{U}$. $f[U]\subseteq V$ means that $x \in U \implies f(x) \in V$. Since we chose $V$ to be a particular disk, we can rewrite this as $x \in U \implies \modulus{f(x)-L} < \varepsilon$. We can rewrite the left hand side to get $(x \in X) \land (x \in \tilde{U}) \implies \modulus{f(x)-L} < \varepsilon$. Since $0 < \modulus{x-p}< \delta \implies x \in \tilde{U}$, we have $(x \in X) \land (0 < \modulus{x-p} < \delta) \implies \modulus{f(x)-L} < \varepsilon$. Thus, we have that the metric limit of $f$ at $p$ is $L$ if the topological limit of $f$ at $p$ is $L$.\\
\\(Metric $\implies$ Sequential): Suppose $\lim_{x \to p} f(x) = L$ in the metric sense. We want to show it has a sequential limit of $L$ as well. We are given a sequence $\seq{a} \in X \setminus\{p\} \to p$ and must show that the corresponding sequence $f(a_n)$ converges to $L$. In other words, given any $\varepsilon > 0$, we have to show that the output sequence is eventually within $\varepsilon$ of $L$. We know that the function converges to $L$ in a metric fashion, which means that given any $\varepsilon > 0$ there exists a $\delta > 0$ such that $(x \in X) \land (0 < \modulus{x-p} < \delta) \implies \modulus{f(x)-L} < \varepsilon$. We can rewrite the statement on the left hand side as $(x \in X\setminus\{p\}) \land (\modulus{x-p} < \delta)$. Our sequence $a_n$ will satisfy the left condition for all $n$ since the sequence is in $X\setminus\{p\}$, and since it converges to $p$, it will eventually satisfy the right condition for sufficiently large $n$. Our metric convergence property tells us that this means for sufficiently large $n$, $f(a_n)$ will be within $\varepsilon$ of $L$. This is exactly what it means for $f(a_n) \to L$. Thus, we have that sequential limit of $f$ at $p$ is $L$ if the metric limit of $f$ at $p$ is $L$.\\
\\(Sequential $\implies$ Topological): Suppose $\lim_{x \to p} f(x) = L$ in the sequential sense. We want to show it has a topological limit of $L$ as well. Suppose for the sake of contradiction the topological limit is not $L$. That is, there exists some $V$ which is a neighborhood of $L$ such that the image of every relative punctured neighborhood $U \in \rpnbhd{p}{X}$ is not a subset of $V$. Therefore, for any $U \in \rpnbhd{p}{X}$, there exists a point $x_U \in U$ such that $f(x_U) \not\in V$. We'll create a sequence of relative punctured neighborhoods $U_n = \pdisk{p}{1/n} \cap X$. By our previous result, we can pick a sequence of points $x_{U_n}$ such that $f(x_{U_n}) \not\in V$. Since for a sequence to converge to a point it must eventually be inside any neighborhood of that point, $f(x_{U_n})$ doesn't converge to $L$. But because $x_{U_n} \in \pdisk{p}{1/n} \cap X$, we have that $0 < \modulus{x_{U_n}-p} < 1/n$. Since the RHS goes to 0, by the \hyperlink{Squeeze Theorem}{squeeze theorem} so does the LHS, and therefore $x_{U_n} \to p$. Since this sequence converges to $p$ and is in $X\setminus\{p\}$, $f(x_{U_n}) \to L$. But we previously showed that this couldn't be the case. Therefore, there cannot be such a neighborhood $V$, meaning that the limit of $f$ at $p$ is $L$ in the topological sense. 
\end{proof}
\begin{theorem}[Uniqueness of Limits for Functions]
If $\fn{f}{X\subseteq\C}{\C}$ has a limit of $L$ at $p \in \overline{X}$ then it has no other limit.
\end{theorem}
\begin{proof}
This follows directly from the uniqueness of limits for sequences and the sequential definition of the limit of a function.
\end{proof}
\begin{theorem}[Limit Laws for Functions]
If $\fn{f}{X\subseteq\C}{\C}$ has a limit of $L$ at $p \in \overline{X}$ and $\fn{g}{X\subseteq\C}{\C}$ has a limit of $M$ at $p \in \overline{X}$ then the following apply:
\begin{enumerate}
\item $$\lim_{x \to p} (f(x)+g(x)) = L+M$$
\item $$\lim_{x \to p} (f(x)g(x)) = LM$$
\item $$\lim_{x \to p} \frac{1}{g(x)} = \frac{1}{M}$$\\
provided $M \neq 0$.
\item $$\lim_{x \to p} \rpart{f(x)} = \rpart{L}$$\\$$\lim_{x \to p} \ipart{f(x)} = \ipart{L}$$
\item $$\lim_{x \to p} \modulus{f(x)} = \modulus{L}$$
\end{enumerate}
\end{theorem}
\begin{proof}
These results follow rather directly from the sequential definition of the limit of a function and the limit laws of sequences. For instance, given any sequence of $x_n \in X\setminus\{p\}$ converging to $p$, the limit of $f(x_n)+g(x_n)$ is the sum of the limits, i.e. $L+M$. However, the reciprocal law introduces one minor complication: the domain of $\frac{1}{g(x)}$ can be smaller than the domain of $g(x)$. If we have a sequence converging to $p$ which never hits a zero of $g(x)$, and therefore is in the domain of $\frac{1}{g(x)}$, we can use the reciprocal law to show that the limit of the output sequence is $\frac{1}{M}$. However, we need to show that there actually \emph{exist} such sequences. Suppose every sequence which approaches $p$ contains a zero of $g(x)$. Then for any disk around $p$, there exists a zero of $g(x)$ inside it. If there was some disk where this wasn't the case, we could have a sequence in that disk approach $p$ without touching a zero of $g(x)$. We can then choose a sequence of disks whose radii go to zero, and pick a zero of $g(x)$ from each disk to get a sequence of points going to $p$. Since plugging any sequence member into $g$ gives zero, the limit of the output sequence is zero, contradicting our assumption that $M \neq 0$. Therefore, there are some sequences that never hit a zero, and therefore the limit rule applies.
\end{proof}
\subsection{Continuity}
\subsubsection{Basic Properties of Continuous Functions}
\subsubsection{Topological Properties of Continuous Functions}
\subsubsection{Uniform Continuity}
\subsection{The Theory of Paths}
While writing this book, we came to realize that a surprisingly large amount of complex analysis is based on the topological and analytical properties of \emph{paths} in the complex plane. Indeed, much of algebraic topology, which we will examine closely in Chapter 7, is based on characterizing topological spaces based on what types of paths (and their close relatives, called \emph{patches}) the topological space admits. For this reason, we thought that the rigorous development of the theory of paths should be its own subsection.
\subsubsection{Topological Results on Paths}
\begin{definition}[Path]
Suppose $X$ is a topological space. Then a \emph{path} $\fn{\gamma}{[0,1]}{X}[C^0]$ is simply a continuous function from the unit interval into the topological space. The set of all paths in a set $X$ is denoted $\mathcal{P}_X$.
\end{definition}
\begin{definition}[Loop]
A \emph{loop} $\gamma$ is simply a path that ends where it starts, i.e. $\gamma(0) = \gamma(1)$.
\end{definition}
\begin{definition}[Reversal of a Path]
Suppose $\gamma$ is a path. The \emph{reversal} of $\gamma$, written $\gamma^\dashv$, is defined as $\gamma^\dashv (t) = \gamma (1-t)$.
\end{definition}
\begin{lemma}[Reversal of a Path is a Path]
If $\gamma$ is a path, then so is $\gamma^\dashv$.
\end{lemma}
\begin{lemma}[Reversal of a Loop is a Loop]
If $\gamma$ is a loop, then so is $\gamma^\dashv$.
\end{lemma}
\begin{definition}[Concatenation of Paths]
Suppose $\gamma$ and $\delta$ are two paths with $\gamma(1)=\delta(0)$. Then we define the \emph{concatenation} of the two paths, $\gamma^\frown\delta$ is defined as follows:
\begin{equation*}
\gamma^\frown\delta(t) = 
\begin{cases}
\gamma(2t) & t \leq 1/2\\
\delta(2t-1) & t \geq 1/2
\end{cases}
\end{equation*}
\end{definition}
\begin{lemma}[Concatenation of Paths is a Path]
If $\gamma$ and $\delta$ are paths, then so is $\gamma^\frown\delta$.
\end{lemma}
\begin{lemma}[Reversal of a Concatenation]
If $\gamma^\frown\delta$ is a valid concatenation, then $(\gamma^\frown\delta)^\dashv = (\delta^\dashv)^\frown(\gamma^\dashv)$.
\end{lemma}
\begin{lemma}[Concatenation of Loops is a Loop]
If $\gamma$ and $\delta$ are loops, then so is $\gamma^\frown\delta$.
\end{lemma}
\begin{definition}[Uniform Rectilinear Motion]
For any two points in the complex plane $z$ and $w$, there is a special path between them called the \emph{uniform rectilinear motion}. We define it as $\overrightarrow{z,w}(t)=(1-t)z+tw$.
\end{definition}
\begin{definition}[Path Connectedness]
A set $X$ is called \emph{path connected} if for any two points in the set there is a path in the set that starts at one and ends at the other.
\end{definition}
\begin{theorem}[Path Connected Sets are Connected]
If a set is path connected, then it is connected.
\end{theorem}
\begin{corollary}[The Complex Plane is Connected]
The complex plane $\C$ is connected
\end{corollary}
\begin{corollary}
The only subsets of the complex plane which are both open and closed (sometimes called \emph{clopen}) are the empty set and the complex plane itself.
\end{corollary}
\begin{proof}
Suppose $X \subseteq \C$ is a clopen set. Since it is both open and closed, its complement $X^C$ is also both open and closed. We therefore have that $X$ and $X^C$ are open, their union is the whole complex plane, and their intersection is the empty set. But since the complex plane is connected, the only way this could happen is if one of the sets was the empty set. The complement of the empty set is the whole complex plane.
These are the only clopen subsets of the complex plane.
\end{proof}
\begin{theorem}[Regions are Path Connected]
Every region is a path connected set.
\end{theorem}
\begin{definition}[Zig-Zag Path]
A path in a set $X$ is called \emph{zig-zag} if it is a member of the set $\mathcal{Z}_X$ which we define as follows:
\begin{enumerate}
\item If the uniform rectilinear motion between two points in $X$ with the same real part is contained in $X$, then the uniform rectilinear motion is in $\mathcal{Z}_X$.
\item If the uniform rectilinear motion between two points in $X$ with the same imaginary part is contained in $X$, then the uniform rectilinear motion is in $\mathcal{Z}_X$.
\item Given any $\gamma, \delta \in \mathcal{Z}_X$ with $\gamma(1)=\delta(0)$, then the concatenation $\gamma^\frown\delta$ is in $\mathcal{Z}_X$.
\item The set $\mathcal{Z}_X$ is the minimal such set of paths in $X$ satisfying the previous requirements. That is, given any subset of $\mathcal{P}_X$ which contains all possible vertical and horizontal uniform rectilinear motions and is closed under concatenation, $\mathcal{Z}_X$ will be a subset of this set.
\end{enumerate}
\end{definition}
\begin{theorem}[Reversal of a Zig-Zag]
If $\gamma \in \mathcal{Z}_X$, then $\gamma^\vdash \in \mathcal{Z}_X$.
\end{theorem}
\begin{proof}
First, we'll define the set $R \subseteq \mathcal{Z}_X (\subseteq \mathcal{P}_X)$ as the set of all zig-zag paths whose reversal is also a zig-zag path. We need to show that this set is identical to the set of all zig-zag paths. First, consider any purely horizontal rectilinear motion $\overrightarrow{z,w}$ which is a zig-zag path in $X$. This is defined as $\overrightarrow{z,w}(t) = (1-t)z + tw$. By definition, its reversal is $\overrightarrow{z,w}^\vdash (t) = tz + (1-t)w = \overrightarrow{w,z} (t)$. Since the image of the reversal of a path is the same as the original image of the path, this path doesn't leave the set $X$. Since it is still purely horizontal, it is a zig-zag path in $X$ and therefore a member of our set $R$. The same logic shows that every purely vertical uniform rectilinear motion is in $R$ as well. Now we'll take $\gamma, \delta \in R$ where $\gamma(1) = \delta(0)$ and look at the concatenation, $\gamma^\frown\delta$. By \hyperlink{Reversal of a Concatenation}{a previous result}, the reversal of this path is the concatenation $(\delta^\vdash)^\frown(\gamma^\vdash)$. Since the two original paths were in $R$, their reversals are also zig-zag paths, and since the concatenation of two zig-zag paths is a zig-zag path, this one is as well. Therefore, the concatenation of two elements of $R$ is also an element in $R$. By our minimality condition for zig-zag paths, this means $R\supseteq\mathcal{Z}_X$. But since we originally constructed $R$ to be a subset of $\mathcal{Z}_X$, we have $R=\mathcal{Z}_X$, and therefore the reversal of \emph{any} zig-zag path is a zig-zag path in the same set.
\end{proof}
\begin{definition}[Zig-Zag Connectedness]
A set $X$ is called \emph{zig-zag connected} if for any two points in the set there is a zig-zag path in the set that starts at one and ends at the other.
\end{definition}
\begin{theorem}[Zig-Zag Connected Sets are Connected]
If a set is zig-zag connected, then it is connected.
\end{theorem}
\begin{theorem}[Regions are Zig-Zag Connected]
Every region is a zig-zag connected set.
\end{theorem}
\subsubsection{Winding Numbers of Paths}
The concept of the \emph{index} or \emph{winding number} of a path with respect to a point is an essential part of many of the results we will prove in later sections. The idea of a winding number is often first analyzed in the context of only those \emph{loops} satisfying certain smoothness conditions which we will examine in our section on contours. However, the notion of a winding number is not unique to loops, nor does it require the path to be smooth. Therefore, we thought that we should introduce the idea in the most general context, and prove the typical results on the winding numbers of smooth loops as theorems in later sections.
\begin{definition}[Winding Number]
Suppose $\gamma$ is a path in $\C$, and suppose $z \in \C$ and $z \not\in \range{\gamma}$. If there exists a path in the \emph{reals} $\Theta$ which satisfies the following equation:
\begin{equation*}
\frac{\gamma(t)-z}{\modulus{\gamma(t)-z}} = e^{i\Theta(t)}
\end{equation*}
then we can define the \emph{winding number} of $\gamma$ with respect to $z$ as $\ind{z}{\gamma} = \frac{\Theta(1)-\Theta(0)}{2\pi}$. The real-valued path $\Theta$ is called an \emph{continuous angle function} for the path $\gamma$.
\end{definition}